{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafathebull/Rafathebull/blob/main/Task1_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "hMVTbUhPrpWS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "task_1a_dataframe = pd.read_csv('/content/drive/MyDrive/task_1a_dataset.csv')\n",
        "def data_preprocessing(task_1a_dataframe):\n",
        "    # Create a copy of the original dataframe to avoid modifying the original data\n",
        "    encoded_dataframe = task_1a_dataframe.copy()\n",
        "\n",
        "    # Initialize a LabelEncoder for encoding categorical features\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Iterate through columns in the dataframe\n",
        "    for column in encoded_dataframe.columns:\n",
        "        # Check if the column data type is object (textual)\n",
        "        if encoded_dataframe[column].dtype == 'object':\n",
        "            # Encode the textual feature into numerical labels\n",
        "            encoded_dataframe[column] = label_encoder.fit_transform(encoded_dataframe[column])\n",
        "\n",
        "    return encoded_dataframe\n",
        "\n",
        "encoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
        "\n",
        "def identify_features_and_targets(encoded_dataframe):\n",
        "    features = ['Education','ExperienceInCurrentDomain','PaymentTier','Age','City','Gender']\n",
        "    target = 'LeaveOrNot'\n",
        "    features_and_targets = [features, target]\n",
        "\n",
        "    return features_and_targets\n",
        "features_and_targets = identify_features_and_targets(encoded_dataframe)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hm28Bd7OMeN",
        "outputId": "25c863ae-ead6-4664-b7fc-fd85149c096b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_as_tensors(features_and_targets):\n",
        "    # Extract features and target label from the input list\n",
        "    features, target = features_and_targets\n",
        "\n",
        "    # Assuming you have your data loaded and split into X_train, X_test, y_train, y_test\n",
        "    # Convert NumPy arrays to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "    # Create a TensorDataset for training data\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "    # Create a DataLoader for training data to make it iterable\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Return the tensors and iterable training data\n",
        "    tensors_and_iterable_training_data = [X_train_tensor, y_train_tensor, train_loader]\n",
        "\n",
        "    return tensors_and_iterable_training_data\n",
        "\n",
        "    features = ['Education','ExperienceInCurrentDomain','PaymentTier','Age','City','Gender']\n",
        "    target = 'LeaveOrNot'\n",
        "    features_and_targets = [features, target]\n",
        "    tensors_and_iterable_training_data = load_as_tensors(features_and_targets)"
      ],
      "metadata": {
        "id": "NN-32s9Zrv4h"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn model"
      ],
      "metadata": {
        "id": "A3JvEQQ7UBSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Salary_Predictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Salary_Predictor, self).__init__()\n",
        "\n",
        "        # Define the layers of the neural network\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Define the activation functions and how data flows through the layers\n",
        "        '''\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "# Assuming input size is 3, hidden size is 64, and output size is 1\n",
        "model = Salary_Predictor(input_size=6, hidden_size=64, output_size=1)"
      ],
      "metadata": {
        "id": "T5zgZ3FRr_RI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_loss_function():\n",
        "    loss_function = nn.MSELoss()\n",
        "\n",
        "    return loss_function\n",
        "\n",
        "# Example usage:\n",
        "loss_function = model_loss_function()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "def model_optimizer(model):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have already created an instance of the 'Salary_Predictor' model\n",
        "model = Salary_Predictor(input_size=6, hidden_size=64, output_size=1)\n",
        "optimizer = model_optimizer(model)\n"
      ],
      "metadata": {
        "id": "ynwyzICCsIzl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_number_of_epochs():\n",
        "    number_of_epochs = 100\n",
        "    return number_of_epochs\n",
        "\n",
        "# Example usage:\n",
        "number_of_epochs = model_number_of_epochs()\n",
        "\n"
      ],
      "metadata": {
        "id": "OU9V_hJIsODA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
        "    X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader = tensors_and_iterable_training_data\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the total loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Print the average loss for this epoch\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/{number_of_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have already defined the required parameters\n",
        "    tensors_and_iterable_training_data = [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader]\n",
        "\n",
        "    return tensors_and_iterable_training_data\n",
        "    features = ['Education','ExperienceInCurrentDomain','PaymentTier','Age','City','Gender']\n",
        "    target = 'LeaveOrNot'\n",
        "    features_and_targets = [features, target]\n",
        "    tensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
        "    trained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer)\n"
      ],
      "metadata": {
        "id": "mXv7SxMYscWr"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
        "    X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader = tensors_and_iterable_training_data\n",
        "\n",
        "    trained_model.eval()  # Set the model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking for evaluation\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            # Forward pass\n",
        "            outputs = trained_model(batch_X)\n",
        "\n",
        "            # Convert the model's predictions to class labels (e.g., 0 or 1)\n",
        "            predicted_labels = (outputs >= 0.5).float()\n",
        "\n",
        "            # Count correct predictions\n",
        "            correct_predictions += (predicted_labels == batch_y).sum().item()\n",
        "            total_samples += batch_y.size(0)\n",
        "    # Calculate accuracy\n",
        "    model_accuracy = (correct_predictions / total_samples)\n",
        "    return model_accuracy\n"
      ],
      "metadata": {
        "id": "5rXAxZgPsiHe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and load your data, model, loss function, and optimizer\n",
        "features_and_targets = identify_features_and_targets(encoded_dataframe)\n",
        "tensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
        "model = Salary_Predictor(input_size=3, hidden_size=64, output_size=1)\n",
        "loss_function = model_loss_function()\n",
        "optimizer = model_optimizer(model)\n",
        "number_of_epochs = model_number_of_epochs()\n",
        "\n",
        "# Train the model\n",
        "trained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer)\n",
        "\n",
        "# Validate the model\n",
        "model_accuracy = validation_function(trained_model, tensors_and_iterable_training_data)\n",
        "print(f'Model Accuracy on Validation Dataset: {model_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "qhLS9DG4smxY",
        "outputId": "42591ae6-8a76-4a3f-ac96-b16295bf7139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1062cbfec45c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define and load your data, model, loss function, and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_and_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentify_features_and_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtensors_and_iterable_training_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_as_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_and_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSalary_Predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-80e399350602>\u001b[0m in \u001b[0;36mload_as_tensors\u001b[0;34m(features_and_targets)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Assuming you have your data loaded and split into X_train, X_test, y_train, y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Convert NumPy arrays to PyTorch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_train_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your data from a CSV file or another source into a DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/task_1a_dataset.csv')\n",
        "\n",
        "# Define your features and target variable\n",
        "features = ['Education','ExperienceInCurrentDomain','PaymentTier','Age','City','Gender']\n",
        "target = 'LeaveOrNot'\n",
        "\n",
        "# Check data types of columns\n",
        "non_numeric_columns = data.select_dtypes(exclude=['float', 'int']).columns\n",
        "batch_size = 100\n",
        "# Handle non-numeric columns (e.g., label encoding)\n",
        "label_encoders = {}\n",
        "for column in non_numeric_columns:\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "    data[column] = label_encoders[column].fit_transform(data[column])\n",
        "\n",
        "# Split your data into training and testing sets\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert your training and testing data into tensors\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Create a TensorDataset for training data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Create a DataLoader for training data to make it iterable\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Return the tensors and iterable training data\n",
        "tensors_and_iterable_training_data = [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader]\n"
      ],
      "metadata": {
        "id": "8B6rO-k9Nf2Q"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7MoB4-KeNWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and load your data, model, loss function, and optimizer\n",
        "features = ['Education','ExperienceInCurrentDomain','PaymentTier','Age','City','Gender']\n",
        "target = 'LeaveOrNot'\n",
        "features_and_targets = [features, target]\n",
        "\n",
        "# Assuming you have your data loaded and preprocessed, split into X_train, X_test, y_train, y_test\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 100  # You can adjust this value based on your needs\n",
        "\n",
        "# Create a TensorDataset for training data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Create a DataLoader for training data to make it iterable\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Return the tensors and iterable training data\n",
        "tensors_and_iterable_training_data = [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader]\n",
        "\n",
        "model = Salary_Predictor(input_size=len(features), hidden_size=64, output_size=1)\n",
        "loss_function = model_loss_function()\n",
        "optimizer = model_optimizer(model)\n",
        "number_of_epochs = model_number_of_epochs()\n",
        "\n",
        "# Train the model\n",
        "trained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Validate the model\n",
        "model_accuracy = validation_function(trained_model, tensors_and_iterable_training_data)\n",
        "print(f'Model Accuracy on Validation Dataset: {model_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf1RnBOkJmbi",
        "outputId": "047cd455-eae7-4c36-a5e5-230eeb0f0f25"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.2371\n",
            "Epoch [2/100], Loss: 0.2283\n",
            "Epoch [3/100], Loss: 0.2273\n",
            "Epoch [4/100], Loss: 0.2258\n",
            "Epoch [5/100], Loss: 0.2227\n",
            "Epoch [6/100], Loss: 0.2255\n",
            "Epoch [7/100], Loss: 0.2243\n",
            "Epoch [8/100], Loss: 0.2239\n",
            "Epoch [9/100], Loss: 0.2265\n",
            "Epoch [10/100], Loss: 0.2298\n",
            "Epoch [11/100], Loss: 0.2260\n",
            "Epoch [12/100], Loss: 0.2249\n",
            "Epoch [13/100], Loss: 0.2241\n",
            "Epoch [14/100], Loss: 0.2241\n",
            "Epoch [15/100], Loss: 0.2248\n",
            "Epoch [16/100], Loss: 0.2259\n",
            "Epoch [17/100], Loss: 0.2239\n",
            "Epoch [18/100], Loss: 0.2262\n",
            "Epoch [19/100], Loss: 0.2274\n",
            "Epoch [20/100], Loss: 0.2228\n",
            "Epoch [21/100], Loss: 0.2256\n",
            "Epoch [22/100], Loss: 0.2257\n",
            "Epoch [23/100], Loss: 0.2254\n",
            "Epoch [24/100], Loss: 0.2270\n",
            "Epoch [25/100], Loss: 0.2228\n",
            "Epoch [26/100], Loss: 0.2282\n",
            "Epoch [27/100], Loss: 0.2258\n",
            "Epoch [28/100], Loss: 0.2269\n",
            "Epoch [29/100], Loss: 0.2236\n",
            "Epoch [30/100], Loss: 0.2289\n",
            "Epoch [31/100], Loss: 0.2296\n",
            "Epoch [32/100], Loss: 0.2252\n",
            "Epoch [33/100], Loss: 0.2258\n",
            "Epoch [34/100], Loss: 0.2266\n",
            "Epoch [35/100], Loss: 0.2249\n",
            "Epoch [36/100], Loss: 0.2224\n",
            "Epoch [37/100], Loss: 0.2273\n",
            "Epoch [38/100], Loss: 0.2279\n",
            "Epoch [39/100], Loss: 0.2261\n",
            "Epoch [40/100], Loss: 0.2252\n",
            "Epoch [41/100], Loss: 0.2261\n",
            "Epoch [42/100], Loss: 0.2257\n",
            "Epoch [43/100], Loss: 0.2275\n",
            "Epoch [44/100], Loss: 0.2239\n",
            "Epoch [45/100], Loss: 0.2265\n",
            "Epoch [46/100], Loss: 0.2280\n",
            "Epoch [47/100], Loss: 0.2269\n",
            "Epoch [48/100], Loss: 0.2252\n",
            "Epoch [49/100], Loss: 0.2253\n",
            "Epoch [50/100], Loss: 0.2257\n",
            "Epoch [51/100], Loss: 0.2241\n",
            "Epoch [52/100], Loss: 0.2293\n",
            "Epoch [53/100], Loss: 0.2283\n",
            "Epoch [54/100], Loss: 0.2256\n",
            "Epoch [55/100], Loss: 0.2241\n",
            "Epoch [56/100], Loss: 0.2250\n",
            "Epoch [57/100], Loss: 0.2258\n",
            "Epoch [58/100], Loss: 0.2251\n",
            "Epoch [59/100], Loss: 0.2278\n",
            "Epoch [60/100], Loss: 0.2246\n",
            "Epoch [61/100], Loss: 0.2239\n",
            "Epoch [62/100], Loss: 0.2235\n",
            "Epoch [63/100], Loss: 0.2254\n",
            "Epoch [64/100], Loss: 0.2236\n",
            "Epoch [65/100], Loss: 0.2239\n",
            "Epoch [66/100], Loss: 0.2269\n",
            "Epoch [67/100], Loss: 0.2268\n",
            "Epoch [68/100], Loss: 0.2256\n",
            "Epoch [69/100], Loss: 0.2259\n",
            "Epoch [70/100], Loss: 0.2256\n",
            "Epoch [71/100], Loss: 0.2255\n",
            "Epoch [72/100], Loss: 0.2252\n",
            "Epoch [73/100], Loss: 0.2239\n",
            "Epoch [74/100], Loss: 0.2239\n",
            "Epoch [75/100], Loss: 0.2264\n",
            "Epoch [76/100], Loss: 0.2242\n",
            "Epoch [77/100], Loss: 0.2265\n",
            "Epoch [78/100], Loss: 0.2259\n",
            "Epoch [79/100], Loss: 0.2268\n",
            "Epoch [80/100], Loss: 0.2236\n",
            "Epoch [81/100], Loss: 0.2276\n",
            "Epoch [82/100], Loss: 0.2273\n",
            "Epoch [83/100], Loss: 0.2283\n",
            "Epoch [84/100], Loss: 0.2256\n",
            "Epoch [85/100], Loss: 0.2304\n",
            "Epoch [86/100], Loss: 0.2290\n",
            "Epoch [87/100], Loss: 0.2274\n",
            "Epoch [88/100], Loss: 0.2274\n",
            "Epoch [89/100], Loss: 0.2244\n",
            "Epoch [90/100], Loss: 0.2266\n",
            "Epoch [91/100], Loss: 0.2239\n",
            "Epoch [92/100], Loss: 0.2258\n",
            "Epoch [93/100], Loss: 0.2271\n",
            "Epoch [94/100], Loss: 0.2237\n",
            "Epoch [95/100], Loss: 0.2250\n",
            "Epoch [96/100], Loss: 0.2242\n",
            "Epoch [97/100], Loss: 0.2229\n",
            "Epoch [98/100], Loss: 0.2269\n",
            "Epoch [99/100], Loss: 0.2251\n",
            "Epoch [100/100], Loss: 0.2280\n",
            "Model training complete.\n",
            "Model Accuracy on Validation Dataset: 65.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define your model, loss function, optimizer, and other parameters\n",
        "# (I'll assume you have these defined as functions)\n",
        "\n",
        "# Define and load your data, model, loss function, and optimizer\n",
        "features = ['Education', 'ExperienceInCurrentDomain', 'PaymentTier', 'Age', 'City', 'Gender']\n",
        "target = 'LeaveOrNot'\n",
        "features_and_target = [features, target]\n",
        "\n",
        "# Assuming you have your data loaded and preprocessed, split into X_train, X_test, y_train, y_test\n",
        "X_train_tensor = torch.tensor(X_train[features].values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train[target].values, dtype=torch.float32)  # Reshape target\n",
        "X_test_tensor = torch.tensor(X_test[features].values.reshape(-1, 1), dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test[target].values.reshape(-1, 1), dtype=torch.float32)  # Reshape target\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 100  # You can adjust this value based on your needs\n",
        "\n",
        "# Create a TensorDataset for training data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Create a DataLoader for training data to make it iterable\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Return the tensors and iterable training data\n",
        "tensors_and_iterable_training_data = [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader]\n",
        "\n",
        "model = Salary_Predictor(input_size=len(features), hidden_size=64, output_size=1)\n",
        "loss_function = model_loss_function()\n",
        "optimizer = model_optimizer(model)\n",
        "number_of_epochs = model_number_of_epochs()\n",
        "\n",
        "# Train the model\n",
        "trained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Validate the model\n",
        "model_accuracy = validation_function(trained_model, tensors_and_iterable_training_data)\n",
        "print(f'Model Accuracy on Validation Dataset: {model_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "HoMl4ImhYD04",
        "outputId": "49fd5483-e00f-47b5-dd6a-5cd25be45469"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'LeaveOrNot'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-e6ab40e8cfd6>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Assuming you have your data loaded and preprocessed, split into X_train, X_test, y_train, y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mX_train_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_train_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0my_test_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'LeaveOrNot'"
          ]
        }
      ]
    }
  ]
}